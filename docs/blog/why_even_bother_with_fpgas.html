<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Why Even Bother With FPGAs? &#8212; Thoughts, et cetera  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=12dfc556" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=a966dca0" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="icon" href="../_static/flying-katakana-man.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="No-ISA is the Best ISA" href="no_isa_is_the_best_isa.html" />
    <link rel="prev" title="Blog" href="index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="why-even-bother-with-fpgas">
<h1>Why Even Bother With FPGAs?<a class="headerlink" href="#why-even-bother-with-fpgas" title="Link to this heading">¶</a></h1>
<p>FPGAs being alternative processors enjoy a fair bit of skepticism, especially
from people higher up in the pyramid of computer abstractions (Software
Engineers and the like). This post is my attempt at trying to persuade the
skeptics by way of an instance where FPGAs blow every other kind of processor
out of the water.</p>
<p><strong>TLDR</strong>; FPGAs can allow full DNN inference at nanosecond latency only limited
by the time it takes for electrons to move across a circuit. In comparison,
CPU/GPUs may only be able to run a couple instructions in nanosecond timeframe,
entire inference will require many million/billion of these instructions.</p>
<section id="fpgas-for-the-unenlightened">
<h2>FPGAs for the Unenlightened<a class="headerlink" href="#fpgas-for-the-unenlightened" title="Link to this heading">¶</a></h2>
<p>FPGAs are circuit emulators. Digital Circuits consists of logic gates and
connections between them, FPGAs emulate logic gates and their connections.</p>
<p>Logic gates can be represented by their <a class="reference external" href="https://en.wikipedia.org/wiki/Truth_table">Truth Table</a>. Truth tables are a form of hash
table where the key is a tuple of binary values corresponding to each input and
output is a single bit representing the output of the gate.  One kind of FPGA
(SRAM-based), emulate logic gates by storing truth tables in memory.</p>
<p>Connections are emulated via Programmable Interconnects. Think of a network
switch, programmable interconnects are pretty much like the same except on a
very low-level. <a class="reference external" href="https://cse.usf.edu/~haozheng/teach/cda4253/doc/fpga-arch-overview.pdf">This document</a>
explains in detail the different VLSI architectures present in modern FPGAs.</p>
<p>A programmer usually does not describe circuits in the form of logic gates, they
use abstractions in the form of HDLs to behaviorally describe operations that a
circuit must perform. A compiler converts/maps HDL programs to FPGA primitives.</p>
<p>As it should be obvious by now, FPGAs are unlike processors. They do not have
any “Instruction Set Architecture”. If there is a need, the programmer must
design and implement an ISA <a class="footnote-reference brackets" href="#fpga-arch" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. FPGAs require thinking of problems as
circuits with inputs and outputs.</p>
</section>
<section id="the-central-argument-for-fpgas">
<h2>The Central Argument for FPGAs<a class="headerlink" href="#the-central-argument-for-fpgas" title="Link to this heading">¶</a></h2>
<p>Now, let’s build the argument.</p>
<p>Deep Neural Networks (DNN) inference on demands a lot of compute and is a pretty
challenging problem. Solutions to this problem manifests in the form of ASIC
accelerators and GPUs. More performance can always be brought by scaling said
processors but of-course there is a limit to how far one can scale. For example,
on the <a class="reference external" href="https://developer.nvidia.com/embedded/jetson-nano">NVIDIA Jetson Nano</a>
the time taken to infer a single image for the CNN model ResNet50 is ~72ms. What
if we needed something much faster, say the same inference in integral
nanoseconds? GPUs/ASICs would only be able to execute a couple instructions in
that timeframe let alone complete the inference. Certainly they won’t suffice.</p>
<p>This requirement is not made up. Nanosecond DNN inference is a real problem
faced by a team at CERN working on the Large Hadron Collider.</p>
<p>Here’s a little description of the problem from their <a class="reference external" href="https://arxiv.org/pdf/2006.10159">paper</a>:</p>
<blockquote>
<div><p><em>The hardware triggering system in a particle detector at the CERN LHC is one
of the most extreme environments one can imagine deploying DNNs. Latency is
restricted to O(1)µs, governed by the frequency of particle collisions and
the amount of on-detector buffers. The system consists of a limited amount of
FPGA resources, all of which are located in underground caverns 50-100 meters
below the ground surface, working on thousands of different tasks in
parallel. Due to the high number of tasks being performed, limited cooling
capabilities, limited space in the cavern, and the limited number of
processors, algorithms must be kept as resource-economic as possible. In
order to minimize the latency and maximize the precision of tasks that can be
performed in the hardware trigger, ML solutions are being explored as fast
approximations of the algorithms currently in use.</em></p>
</div></blockquote>
</section>
<section id="solutions">
<h2>Solutions<a class="headerlink" href="#solutions" title="Link to this heading">¶</a></h2>
<p>There are, broadly speaking, two ways of solving this problem:</p>
<section id="the-asic-way">
<h3>1. The ASIC Way<a class="headerlink" href="#the-asic-way" title="Link to this heading">¶</a></h3>
<p>This includes CPUs/GPUs/TPUs or any other ASIC. The idea would be to to have a
large grid of multipliers and adders to carry out as many multiply-accumulate
operations in parallel. To achieve more performance, research would be put to
increase the frequency of the chip (Moore’s law). Compilers and specialized
frameworks help abstract computation. And if, we need more performance,
specialized engineers (who have mastered assembly language) are called upon to
write performant kernels, making use of clever tricks to have the fastest
possible dot product.</p>
</section>
<section id="the-fpga-way">
<h3>2. The FPGA way<a class="headerlink" href="#the-fpga-way" title="Link to this heading">¶</a></h3>
<p>Through this way, the idea is to exploit FPGA’s programming model. Instead of
writing a program for our problem, we design a circuit for it. Each layer of
a neural network would be represented by a circuit. Inside the layer, all
dot-products themselves are represented by a circuit. If the neural network is
not prohibitively large, we can even fit the entire NN as a combinational
circuit.</p>
<p>As you might have learnt in your digital circuits course, combinational circuits
do not contain any clocks i.e. there’s no notion of frequency — inputs come in,
outputs go out. The speed of computation is only bottleneck’ed by the time it
takes electrons to pass in that chip. How cool is that?!</p>
</section>
</section>
<section id="flaws-with-the-fpga-way">
<h2>Flaws with the FPGA way<a class="headerlink" href="#flaws-with-the-fpga-way" title="Link to this heading">¶</a></h2>
<p>One of the biggest flaw with fitting entire problems on the FPGA is that of
<a class="reference external" href="https://en.wikipedia.org/wiki/Combinatorial_explosion">combinatorial
explosion</a> in
complexity. For example, in order to design a circuit for a multiplier, there
are <a class="reference external" href="https://en.wikipedia.org/wiki/Booth's_multiplication_algorithm">well known algorithms</a> that result
in very efficient multiplier. One can avoid going this route by directly
encoding the multipliers into truth-tables. Instead of calculating the outputs
of a multiplication, we remember and look-it-up. Here’s verilog for a 2-bit
multiplication:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">mul</span> <span class="p">(</span> <span class="nb">input</span> <span class="n">signed</span> <span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">0</span><span class="p">]</span> <span class="n">a</span><span class="p">,</span> <span class="nb">input</span> <span class="n">signed</span> <span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">0</span><span class="p">]</span> <span class="n">b</span><span class="p">,</span> <span class="n">output</span> <span class="n">signed</span> <span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">0</span><span class="p">]</span> <span class="n">out</span><span class="p">);</span>
 <span class="n">assign</span> <span class="n">out</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
 <span class="n">assign</span> <span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">|</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
 <span class="n">assign</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">|</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">|</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
 <span class="n">assign</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">endmodule</span>
</pre></div>
</div>
<p>Each output is just a combination of its inputs.</p>
<p>Here’s the problem: this method of designing multipliers does not scale! The
2bit multiplier takes 4 LUTs (pretty reasonable). But the same for an 8bit
multiplier takes ~18,000 LUTs and 3+ hrs to synthesize (awful). The increase is
at the rate of 2^n. Many large neural networks will have a hard time to fit on
the FPGA in this way.</p>
<p>This doesn’t signal the end for FPGAs, however. There’s still a strong case to be
made for their use—just as the team at CERN has demonstrated. In fact, they are
actively leveraging this potential. They discovered that neural network layers
can be <em>heterogeneously quantized</em> — meaning each layer can have a different
precision level depending on its significance in the computation pipeline, as
outlined in their work <a class="reference external" href="https://fastmachinelearning.org/hls4ml/">here</a></p>
<p>If an entire network cannot fit on an FPGA, fast reconfiguration can provide a
solution. This involves configuring the hardware for one layer, processing its
outputs, then reconfiguring the hardware for the next layer, and so on. The
approach can be further refined to enable reconfiguration at a per-channel
level, allowing smaller FPGAs with limited resources to participate. A
‘compiler’ would orchestrate the computation offline, determining the sequence
and timing of reconfigurations before the actual computation begins.</p>
<p>Recent interest in hyper-quantization i.e. <a class="reference external" href="https://github.com/kyegomez/BitNet">1bit</a>, 2bit, 3bit … networks is a
big win for the FPGA way. The lower the resolution, the more efficient and
practical the solution becomes, making FPGAs a great fit for this approach.</p>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>With the FPGA way, many problems spanning different domains can be solved in
interesting and (sometimes) superior ways. At my workplace, we’ve started
research in the FPGA way, trying to bring it out of the depths of complexities
and solve practical problems.</p>
<p>The intention of this post is not to compare ASICs and FPGAs (comparisons are
futile), but to highlight how FPGAs ought to be seen and used. In the following
few months, i’ll write more on this research as I uncover it myself. I’ll leave
you with some links advocating for the FPGA way <a class="footnote-reference brackets" href="#fpga-way" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<ul class="simple">
<li><p><a class="reference external" href="https://proceedings.mlr.press/v80/chatterjee18a/chatterjee18a.pdf">Learning and Memorization - Satrajit Chatterjee</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.00938">LUTnet</a></p></li>
<li><p><a class="reference external" href="https://scholar.google.com/citations?user=NTn1NJAAAAAJ&amp;hl=en">George Constantinides and his team</a></p></li>
<li><p><a class="reference external" href="https://fastmachinelearning.org/hls4ml/">hls4ml team</a></p></li>
</ul>
<p class="rubric">Footnotes</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="fpga-arch" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>The term “architecture” is a bit overloaded. The first
meaning is of the VLSI sense i.e. how LUTs and interconnect are organized to
make the FPGA. Another usage is for describing what all higher level
components are being designed <strong>on top</strong> of the FPGA. Think matmul engines,
caches etc. “Architecture” has meaning on different levels of circuit design.</p>
</aside>
<aside class="footnote brackets" id="fpga-way" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>The is a term i’ve coined myself. I’ve not seen anyone else use
it in their works.</p>
</aside>
</aside>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Thoughts, et cetera</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sunday.html">Paper Sundays</a></li>
<li class="toctree-l1"><a class="reference internal" href="../links.html">Links</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Blog</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Blog</a></li>
      <li>Next: <a href="no_isa_is_the_best_isa.html" title="next chapter">No-ISA is the Best ISA</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023, Shreeyash Pandey.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/blog/why_even_bother_with_fpgas.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>